{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1699290319904,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"TUaequVH9pF8","outputId":"a9505692-aaa6-4c1a-c5f5-bd6ce07bed3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on CoLab? False\n"]}],"source":["import os\n","is_running_on_colab = 'COLAB_GPU' in os.environ\n","print('Running on CoLab?', is_running_on_colab)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3645,"status":"ok","timestamp":1699290323856,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"8L3Bt81myNxC","outputId":"9648b228-04b6-4141-8eb0-644d6f1c51ff"},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","import xml.etree.ElementTree as ET\n","from torch.utils.data import *\n","from imutils import paths\n","from typing import Union\n","import torch\n","import torch.nn as nn\n","import time\n","import torch.optim as optim\n","from tqdm.notebook import tqdm\n","\n","\n","if is_running_on_colab:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  data_path = '/content/gdrive/MyDrive/license_plate/data/'\n","  test_path = '/content/gdrive/MyDrive/license_plate/testdata/'\n","else:\n","  current_dir = os.getcwd()\n","  data_path = os.path.join(current_dir,'dataset','license_plate','data')\n","  test_path = os.path.join(current_dir,'dataset','license_plate','test_data')\n","#simple directory check for the data_files\n","\n","def check_directories_exist(*paths):\n","    for path in paths:\n","        if not os.path.isdir(path):\n","            assert False\n","            print(f\"The directory {path} does not exist.\")\n","\n","check_directories_exist(data_path, test_path)\n","\n","data_link = \"https://drive.google.com/open?id=1rdEsCUcIUaYOVRkx5IMTRNA7PcGMmSgc\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8KmlcMPjCpiI"},"outputs":[],"source":["\n","class labelFpsDataLoader(Dataset):\n","    def __init__(self, img_dir, imgSize, is_transform=None):\n","        self.img_dir = img_dir\n","        self.img_paths = []\n","        for i in range(len(img_dir)):\n","            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n","        self.img_size = imgSize\n","        self.is_transform = is_transform\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, index):\n","        # Get image name\n","        img_name = self.img_paths[index]\n","        img = cv2.imread(img_name)\n","        # Resize image\n","        resizedImage = cv2.resize(img, self.img_size)\n","        resizedImage = resizedImage.astype('float32')\n","        resizedImage /= 255.0\n","\n","        if is_running_on_colab:\n","            iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n","        else:\n","            iname = img_name.rsplit('\\\\', 1)[-1].rsplit('.', 1)[0].split('-')\n","        [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n","            # [leftUp, rightDown] = [[int(eel) for eel in el.split('_')] for el in iname[1:3]]\n","\n","        # Find leftUp and rightDown from file-name of original image\n","\n","        # Find original width and original height of original image\n","        ori_w, ori_h = [float(int(el)) for el in [img.shape[1], img.shape[0]]]\n","\n","        # Find scale values for width and height\n","        scale_height, scale_width = self.img_size[1] / ori_h, self.img_size[0] / ori_w\n","\n","        scaled_leftUp = (int(leftUp[0] * scale_width), int(leftUp[1] * scale_height))\n","        scaled_rightDown = (int(rightDown[0] * scale_width), int(rightDown[1] * scale_height))\n","\n","        # All four values of leftUp and rightDown scaled in 1 vector\n","        scaled_labels = (scaled_leftUp, scaled_rightDown)\n","        # scaled_labels = [int(leftUp[0] * scale_x, leftUp[1] * scale_y), (rightDown[0] * scale_x, rightDown[1] * scale_y)]\n","\n","        # Flatten scaled_labels into a 1D list\n","        flattened_labels = [coordinate for point in scaled_labels for coordinate in point]\n","\n","        # Convert the 1D list to a tensor and reshape it to (1, 4)\n","        scaled_labels_tensor = torch.tensor(flattened_labels, dtype=torch.float32)\n","\n","\n","        return resizedImage, scaled_labels_tensor, img_name\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699290744372,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"xW--T__29pGG","outputId":"723123b4-a256-4092-9082-860fec832608"},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of dataset: 327\n","Image shape: (224, 224, 3)\n","Labels: tensor([ 98., 105., 123., 111.])\n","Image name: c:\\Users\\au616584\\OneDrive - Aarhus Universitet\\Datalogi\\Deep_learning\\License_plate\\dataset\\license_plate\\data\\0031-1_1-315&547_397&579-397&579_315&577_315&547_397&549-0_0_9_9_24_32_26-128-19.jpg\n","Item retrieval successful.\n","got out here\n"]}],"source":["# Initialize your dataset\n","img_dir = [data_path]  # Replace with actual paths to your image directories\n","img_size = (224, 224)  # Replace with your desired image size\n","dataset = labelFpsDataLoader(img_dir=img_dir, imgSize=img_size)\n","\n","# Test the length of the dataset\n","print(f\"Length of dataset: {len(dataset)}\")\n","\n","# Test getting an item\n","try:\n","    # Retrieve the first item\n","    img, labels, img_name = dataset[0]\n","\n","    # Check the shapes and types\n","    print(f\"Image shape: {img.shape}\")\n","    print(f\"Labels: {labels}\")\n","    print(f\"Image name: {img_name}\")\n","\n","    # If the code reaches this point, the item has been retrieved successfully\n","    print(\"Item retrieval successful.\")\n","except Exception as e:\n","    # If there is any error, print it out\n","    print(f\"An error occurred: {e}\")\n","print(\"got out here\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"AJ_NSb9iP0Rj"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_img_and_boundingbox(image, labels):\n","    numpy_array = image.cpu().detach().numpy()\n","\n","    cv2_image = cv2.cvtColor(numpy_array, cv2.COLOR_RGB2BGR)\n","\n","    # Extract numerical values from tensors and convert to integers\n","    leftUp = (int(labels[0]),int(labels[1]))\n","    rightDown = (int(labels[2]),int(labels[3]))\n","    # Draw rectangle on the image\n","    new_image = cv2.rectangle(cv2_image, leftUp, rightDown, (255, 0, 0), 2)\n","\n","    # Display the image\n","    plt.imshow(new_image)\n","    plt.show()\n","\n","# scaled_labels = batch[1][0]\n","# plot_img_and_boundingbox(image, scaled_labels)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":669,"status":"ok","timestamp":1699290324520,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"Akmn3oBa9pGI","outputId":"e7350baf-76ab-4e67-d26d-1592c4549762"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in C:\\Users\\au616584/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to C:\\Users\\au616584/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_large-8738ca79.pth\n","100%|██████████| 21.1M/21.1M [00:05<00:00, 3.93MB/s]\n"]}],"source":["# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n","# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n","# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n","net = nn.Sequential(\n","    nn.Linear(960, 100),\n","    nn.ReLU(),\n","    nn.Dropout(0.01),\n","    nn.Linear(100, out_features=4, bias=True),\n",")\n","model.classifier = net\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FhpB5DL-T0gw"},"outputs":[],"source":["# net = nn.Sequential(\n","#     nn.Linear(1280, 1024),\n","#     nn.ReLU(),\n","#     nn.Dropout(0.5),\n","#     nn.ReLU(),\n","#     nn.Linear(1024, out_features=4, bias=True),\n","# )\n","net = nn.Sequential(\n","    nn.Linear(960, 100),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.BatchNorm1d(100),\n","    nn.Linear(100, out_features=4, bias=True),\n",")\n","model.classifier = net"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1699290325342,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"dyV_mS58Uyay","outputId":"d5eec382-f763-4d9c-fe2b-b14da850b8cb"},"outputs":[{"data":{"text/plain":["MobileNetV3(\n","  (features): Sequential(\n","    (0): ConvBNActivation(\n","      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","    (1): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (16): ConvBNActivation(\n","      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Linear(in_features=960, out_features=100, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=100, out_features=4, bias=True)\n","  )\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#Sets model to training mode,e this is important for layers that have different functionalities depending on training or eval. for example BatchNorm\n","model.train()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1699290325342,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"1SB-5KBQXiej","outputId":"62a7f3b5-8d4f-481b-b3e8-3f373ac18d84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of layers is 176\n","Number of pretrained base layers is 172\n"]}],"source":["layers_of_classifier = 4\n","for i, param in enumerate(model.parameters()):\n","    if i < len(list(model.parameters())) - layers_of_classifier:\n","        param.requires_grad = False\n","    else:\n","        param.requires_grad = True\n","\n","number_of_layers = len(list(enumerate(model.parameters())))\n","print(f\"Total number of layers is {number_of_layers}\")\n","print(f\"Number of pretrained base layers is {number_of_layers - layers_of_classifier}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qsf8PJ72ZFgy"},"outputs":[],"source":["def check_requires_grad():\n","  for name, param in model.named_parameters(): # Just to check\n","    if name.startswith('classifier'):\n","        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n","    if name.startswith('features'):\n","        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# check_requires_grad()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LTwomuz6N5Po"},"outputs":[],"source":["from datetime import datetime\n","def bb_intersection_over_union(boxA, boxB): # https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n","\t# determine the (x, y)-coordinates of the intersection rectangle\n","\txA = max(boxA[0], boxB[0])\n","\tyA = max(boxA[1], boxB[1])\n","\txB = min(boxA[2], boxB[2])\n","\tyB = min(boxA[3], boxB[3])\n","\t# compute the area of intersection rectangle\n","\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\t# compute the area of both the prediction and ground-truth\n","\t# rectangles\n","\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","\t# compute the intersection over union by taking the intersection\n","\t# area and dividing it by the sum of prediction + ground-truth\n","\t# areas - the interesection area\n","\tiou = interArea / float(boxAArea + boxBArea - interArea)\n","\t# return the intersection over union value\n","\treturn iou\n","\n","def calculate_true_positives_in_batch(y_pred, y_batch):\n","  threshold = 0.5\n","  true_positive_amount = 0\n","  for i in range(y_pred.shape[0]):\n","    y_pred_numpy = y_pred[i].cpu().detach().numpy()\n","    y_batch_numpy = y_batch[i].cpu().detach().numpy()\n","    iou = bb_intersection_over_union(y_pred_numpy, y_batch_numpy)\n","    if iou > threshold:\n","      true_positive_amount +=1\n","  return true_positive_amount\n","\n","#wrapper of tqdm to enable toggling it off easily\n","def toggle_tqdm(iterable, use_tqdm=True):\n","  if use_tqdm:\n","    return tqdm(iterable)\n","  else:\n","    return iterable\n","\n","def calculate_loss_and_accuracy(loader):\n","  total_loss = 0\n","  total_true_positives = 0\n","  total_samples = 0\n","\n","  for X_batch_, y_batch, img_name in loader:\n","      X_batch = X_batch_.permute(0,3,1,2).to(device)\n","      y_batch = y_batch.to(device)\n","      y_pred = model(X_batch)\n","\n","      total_true_positives += calculate_true_positives_in_batch(y_pred, y_batch)\n","\n","      loss = loss_fn(y_pred, y_batch)\n","      total_loss += loss.item() * len(y_batch)  # Accumulate scaled loss\n","      total_samples += len(y_batch)  # Accumulate number of samples\n","  sample_loss = total_loss / total_samples  # Calculate average loss\n","  accuracy = total_true_positives / total_samples\n","  return sample_loss, accuracy\n","\n","def save_model(model):\n","  # Get the current time\n","  current_time = datetime.now()\n","\n","  # Format the time in a 'YearMonthDay_HourMinuteSecond' format for the filename\n","  timestamp = current_time.strftime('%Y%m%d_%H%M')\n","  model_path = f'/content/gdrive/MyDrive/license_plate/models/model_weights_{timestamp}.pth'\n","  torch.save(model.state_dict(), model_path)\n","\n","def load_model(path):\n","  model.load_state_dict(torch.load(path))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"15nRrjd3_KGM"},"outputs":[],"source":["# load_model('/content/gdrive/MyDrive/license_plate/models/model_weights_20231106_1410.pth')\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595,"referenced_widgets":["fc7714303330448eb3d75afc5c4bd4f0","bc08c7836a2f43cb9fa0ced343f67dbd","9ec8fb61a04c44c891f8621e16c23394","132cb76d81484b10a012c3dc316b0acc","96b85257e65f4b05a9665fe36059583b","95fd007e2b6b4b82a44293a195baf7e9","c7131d9fbde24ac3852a12431ae46019","5ac5a15ce1954521873567768bfa4229","7a3d3f1d9638402482cc8817a5504b8b","d402d4a540b34ed294b9c1fdcd43f452","6a8687614612458f8e0e23bf0e47de4f"]},"executionInfo":{"elapsed":12148,"status":"error","timestamp":1699290699726,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"I2mUI6H5Arru","outputId":"332b64b7-396f-48ac-a979-922ea4e33168"},"outputs":[{"name":"stdout","output_type":"stream","text":["using device:  cpu\n","Running on subset!\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c5f4ed7981e4409ade04d91f58564e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"DataLoader worker (pid(s) 31288, 25520) exited unexpectedly","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","\u001b[1;31mEmpty\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m test_loss_history, val_loss_history, test_accuracy_history, val_accuracy_history\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Train decoder (initial)\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m save_model(model)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDECODER TRAINING DONE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[1;32mIn[13], line 59\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(n_epochs, optimizer, scheduler, dataloader, validation_loader)\u001b[0m\n\u001b[0;32m     56\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m toggle_tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs), use_tqdm):\n\u001b[0;32m     58\u001b[0m   \u001b[38;5;66;03m# print(\"epoch:\", i)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoggle_tqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Needs to have shape [batch_size, channels, height, width]\u001b[39;49;00m\n","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[1;32mc:\\Users\\au616584\\Anaconda3\\envs\\deep_new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n","\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 31288, 25520) exited unexpectedly"]}],"source":["scaler = torch.cuda.amp.GradScaler()\n","\n","# Determine hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"using device: \", device)\n","\n","# Define dataloader for training\n","data_loader = labelFpsDataLoader([data_path],(500,1000))\n","train_loader = DataLoader(data_loader, batch_size=16, shuffle=True, num_workers=2)\n","\n","test_loader = labelFpsDataLoader([test_path],(500,1000))\n","validation_loader = DataLoader(test_loader, batch_size=64, shuffle=True, num_workers=2)\n","# Determine subset?? (mabeto??)\n","subset = not is_running_on_colab\n","subset = True\n","subset_data = Subset(data_loader, indices=range(327))\n","subset_val = Subset(test_loader, indices=range(100))\n","if subset:\n","  print(\"Running on subset!\")\n","  train_loader =DataLoader(subset_data, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","  train_loader_finetuning =DataLoader(subset_data, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","  validation_loader = DataLoader(subset_val, batch_size=16, shuffle=True, num_workers=2)\n","\n","decoder_epochs = 1\n","n_epochs = 1\n","# dataiter = iter(trainloader)\n","# first_batch = next(dataiter)\n","\n","# # Now you can access the data and target tensors\n","# X_batch, y_batch, img_name = first_batch\n","\n","# print(X_batch.shape)\n","# Define dataloader for validation\n","\n","# Define model and hyperparameters\n","loss_fn = nn.MSELoss()\n","optimizer_decoder = optim.AdamW(model.parameters(), lr=0.001)\n","#We believe the scheduler LR overrules adam?\n","scheduler_decoder = optim.lr_scheduler.CyclicLR(optimizer_decoder,base_lr=0.01, max_lr=5, cycle_momentum=False)\n","\n","# scheduler_decoder = optim.lr_scheduler.OneCycleLR(optimizer_decoder, max_lr=0.01,total_steps=decoder_epochs)\n","\n","optimizer_full = optim.AdamW(model.parameters(), lr=0.00005)\n","# scheduler_full = optim.lr_scheduler.OneCycleLR(optimizer_decoder, max_lr=0.001,total_steps=n_epochs)\n","scheduler_full = optim.lr_scheduler.CyclicLR(optimizer_decoder,base_lr=0.0001, max_lr=0.1, cycle_momentum=False)\n","model.train()\n","model.to(device)\n","\n","use_tqdm = True\n","# Train\n","def train_model(n_epochs, optimizer, scheduler, dataloader,validation_loader):\n","  test_loss_history = []\n","  val_loss_history = []\n","  test_accuracy_history = []\n","  val_accuracy_history = []\n","  i = 0\n","  for epoch in toggle_tqdm(range(n_epochs), use_tqdm):\n","    # print(\"epoch:\", i)\n","    for X_batch, y_batch, img_name in toggle_tqdm(dataloader, False):\n","      optimizer.zero_grad()\n","      X_batch = X_batch.permute(0,3,1,2).to(device) # Needs to have shape [batch_size, channels, height, width]\n","      y_batch = y_batch.to(device)\n","      with torch.cuda.amp.autocast():\n","        y_pred = model(X_batch)\n","        loss = loss_fn(y_pred,y_batch)\n","      scaler.scale(loss).backward()\n","      scaler.step(optimizer)\n","      scaler.update()\n","      # loss.backward()\n","      # optimizer.step()\n","    scheduler.step()\n","    # In-sample & out-sample loss calculation\n","    model.eval()  # Switch to evaluation mode to disable features like dropout\n","    #time the following\n","\n","    if epoch % 10 == 0:\n","      with torch.no_grad():  # Disable gradient calculation to save memory\n","          # In sample\n","          in_sample_loss, in_sample_accuracy = calculate_loss_and_accuracy(dataloader)\n","          test_loss_history.append(in_sample_loss)\n","          test_accuracy_history.append(in_sample_accuracy)\n","          # print(f'Epoch {epoch+1}, In-sample Loss : {in_sample_loss:.4f}, In-sample accuracy : {in_sample_accuracy:.4f}' )\n","\n","          # Out sample\n","          out_sample_loss, out_sample_accuracy = calculate_loss_and_accuracy(validation_loader)\n","          val_loss_history.append(out_sample_loss)\n","          val_accuracy_history.append(out_sample_accuracy)\n","          tqdm.write(f'Epoch {epoch+1}, Out-sample Loss: {out_sample_loss:.4f}, Out-sample accuracy : {out_sample_accuracy:.4f}')\n","          tqdm.write(f'Epoch {epoch+1}, In-sample Loss: {in_sample_loss:.4f}, In-sample Accuracy: {in_sample_accuracy:.4f}')\n","    i += 1\n","\n","  return test_loss_history, val_loss_history, test_accuracy_history, val_accuracy_history\n","\n","# Train decoder (initial)\n","train_model(decoder_epochs, optimizer_decoder, scheduler_decoder,train_loader, validation_loader)\n","save_model(model)\n","print(\"DECODER TRAINING DONE\")\n","# Unfreeze encoder\n","for i, param in enumerate(model.parameters()):\n","  param.requires_grad = True\n","\n","# Train encoder\n","test_loss_history, val_loss_history, test_accuracy_history, val_accuracy_history = train_model(n_epochs, optimizer_full, scheduler_full,train_loader_finetuning, validation_loader)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1699290699730,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"pkuxBNA391kU"},"outputs":[],"source":["save_model(model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1699290699731,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"lD97FfcQlN5t"},"outputs":[],"source":["# initial_lr = 0.00001\n","# lr_epochs = 100\n","# optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n","\n","\n","# lr_hist = []\n","# train_loss_history = []\n","\n","# def train_model(n_epochs):\n","#   i = 0\n","#   lr = initial_lr\n","#   for epoch in toggle_tqdm(range(n_epochs), use_tqdm):\n","#     # print(\"epoch:\", i)\n","#     for X_batch, y_batch, img_name in toggle_tqdm(trainloader, False):\n","#       agg_loss = 0\n","#       X_batch = X_batch.permute(0,3,1,2).to(device) # Needs to have shape [batch_size, channels, height, width]\n","#       y_batch = y_batch.to(device)\n","#       y_pred = model(X_batch)\n","#       loss = loss_fn(y_pred,y_batch)\n","#       optimizer.zero_grad()\n","#       loss.backward()\n","#       optimizer.step()\n","#       agg_loss += loss.item()\n","#       train_loss_history.append(agg_loss)\n","\n","#       lr_hist.append(lr)\n","\n","#       lr = 1.1*lr\n","#       for g in optimizer.param_groups:\n","#         g['lr'] = lr\n","#       if lr >= 0.0005:\n","#         break\n","\n","# train_model(3)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1699290699731,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"C64tHl3KjUQW"},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","plt.xscale('log')  # Set the y-axis to a logarithmic scale\n","\n","plt.plot(lr_hist,train_loss_history, label='Train Loss')\n","plt.xlabel('LR')\n","plt.ylabel('Loss')\n","plt.grid(True)\n","plt.legend()  # Add a legend to differentiate between train and validation loss\n","plt.show()\n","print(train_loss_history)\n","print(lr_hist)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1699290699732,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"zK6lBjlVEUyX"},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","#plt.yscale('log')  # Set the y-axis to a logarithmic scale\n","plt.plot(test_loss_history, label='Train Loss')\n","plt.plot(val_loss_history, label='Validation Loss')\n","plt.title('Loss Curve')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid(True)\n","plt.legend()  # Add a legend to differentiate between train and validation loss\n","plt.show()\n","print(val_accuracy_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1699290699732,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"H8s5ea1LC82K"},"outputs":[],"source":["#print a trainset with predicted label\n","# train_loader = DataLoader(data_loader, batch_size=1, shuffle=True, num_workers=1)\n","\n","train_iter = iter(train_loader)\n","\n","batch = next(train_iter)\n","\n","X_batch, y_batch, _ = batch\n","print(X_batch.shape)\n","print(y_batch.shape)\n","\n","image = batch[0][0]\n","labels = batch[1][0]\n","\n","# Get predicted labels\n","X_batch = X_batch.permute(0,3,1,2).to(device)\n","print(X_batch.shape)\n","pred = model(X_batch)\n","\n","plot_img_and_boundingbox(image, labels)\n","plot_img_and_boundingbox(image, pred[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1699290699733,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"RyFhpzW1OwKe"},"outputs":[],"source":["# Print a validation image with its predicted labels\n","\n","validationloader = DataLoader(test_loader, batch_size=1, shuffle=True, num_workers=1)\n","\n","validationloader_iter = iter(validationloader)\n","\n","batch = next(validationloader_iter)\n","\n","X_batch, y_batch, _ = batch\n","print(X_batch.shape)\n","print(y_batch.shape)\n","\n","image = batch[0][0]\n","labels = batch[1][0]\n","\n","# Get predicted labels\n","X_batch = X_batch.permute(0,3,1,2).to(device)\n","print(X_batch.shape)\n","pred = model(X_batch)\n","\n","plot_img_and_boundingbox(image, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1699290699733,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"ytHrhFV8aX-C"},"outputs":[],"source":["plot_img_and_boundingbox(image,pred[0])\n","print(pred)\n","print(calculate_true_positives_in_batch(labels.view(1,4),pred[0].view(1,4))) # Need to change view since we dont have batch"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1699290699733,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"ghHYl7RzIXDF"},"outputs":[],"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/mabeto5p/License_plate/blob/mads_working_branch/license_plate_bounding.ipynb","timestamp":1699028930209}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"132cb76d81484b10a012c3dc316b0acc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d402d4a540b34ed294b9c1fdcd43f452","placeholder":"​","style":"IPY_MODEL_6a8687614612458f8e0e23bf0e47de4f","value":" 37/50 [06:08&lt;02:02,  9.43s/it]"}},"5ac5a15ce1954521873567768bfa4229":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8687614612458f8e0e23bf0e47de4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a3d3f1d9638402482cc8817a5504b8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95fd007e2b6b4b82a44293a195baf7e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96b85257e65f4b05a9665fe36059583b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec8fb61a04c44c891f8621e16c23394":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac5a15ce1954521873567768bfa4229","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a3d3f1d9638402482cc8817a5504b8b","value":37}},"bc08c7836a2f43cb9fa0ced343f67dbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95fd007e2b6b4b82a44293a195baf7e9","placeholder":"​","style":"IPY_MODEL_c7131d9fbde24ac3852a12431ae46019","value":" 74%"}},"c7131d9fbde24ac3852a12431ae46019":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d402d4a540b34ed294b9c1fdcd43f452":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc7714303330448eb3d75afc5c4bd4f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc08c7836a2f43cb9fa0ced343f67dbd","IPY_MODEL_9ec8fb61a04c44c891f8621e16c23394","IPY_MODEL_132cb76d81484b10a012c3dc316b0acc"],"layout":"IPY_MODEL_96b85257e65f4b05a9665fe36059583b"}}}}},"nbformat":4,"nbformat_minor":0}
