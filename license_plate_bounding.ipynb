{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1699290319904,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"TUaequVH9pF8","outputId":"a9505692-aaa6-4c1a-c5f5-bd6ce07bed3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab? True\n"]}],"source":["import os\n","is_running_on_colab = 'COLAB_GPU' in os.environ\n","print('Running on CoLab?', is_running_on_colab)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3645,"status":"ok","timestamp":1699290323856,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"8L3Bt81myNxC","outputId":"9648b228-04b6-4141-8eb0-644d6f1c51ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","import xml.etree.ElementTree as ET\n","from torch.utils.data import *\n","from imutils import paths\n","from typing import Union\n","import torch\n","import torch.nn as nn\n","import time\n","import torch.optim as optim\n","from tqdm.notebook import tqdm\n","\n","\n","if is_running_on_colab:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  data_path = '/content/gdrive/MyDrive/license_plate/data/'\n","  test_path = '/content/gdrive/MyDrive/license_plate/testdata/'\n","else:\n","  current_dir = os.getcwd()\n","  data_path = os.path.join(current_dir,'dataset','license_plate','data')\n","  test_path = os.path.join(current_dir,'dataset','license_plate','test_data')\n","#simple directory check for the data_files\n","\n","def check_directories_exist(*paths):\n","    for path in paths:\n","        if not os.path.isdir(path):\n","            assert False\n","            print(f\"The directory {path} does not exist.\")\n","\n","check_directories_exist(data_path, test_path)\n","\n","data_link = \"https://drive.google.com/open?id=1rdEsCUcIUaYOVRkx5IMTRNA7PcGMmSgc\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KmlcMPjCpiI"},"outputs":[],"source":["\n","class labelFpsDataLoader(Dataset):\n","    def __init__(self, img_dir, imgSize, is_transform=None):\n","        self.img_dir = img_dir\n","        self.img_paths = []\n","        for i in range(len(img_dir)):\n","            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n","        self.img_size = imgSize\n","        self.is_transform = is_transform\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, index):\n","        # Get image name\n","        img_name = self.img_paths[index]\n","        img = cv2.imread(img_name)\n","        # Resize image\n","        resizedImage = cv2.resize(img, self.img_size)\n","        resizedImage = resizedImage.astype('float32')\n","        resizedImage /= 255.0\n","\n","        if is_running_on_colab:\n","            iname = img_name.rsplit('/', 1)[-1].rsplit('.', 1)[0].split('-')\n","        else:\n","            iname = img_name.rsplit('\\\\', 1)[-1].rsplit('.', 1)[0].split('-')\n","        [leftUp, rightDown] = [[int(eel) for eel in el.split('&')] for el in iname[2].split('_')]\n","            # [leftUp, rightDown] = [[int(eel) for eel in el.split('_')] for el in iname[1:3]]\n","\n","        # Find leftUp and rightDown from file-name of original image\n","\n","        # Find original width and original height of original image\n","        ori_w, ori_h = [float(int(el)) for el in [img.shape[1], img.shape[0]]]\n","\n","        # Find scale values for width and height\n","        scale_height, scale_width = self.img_size[1] / ori_h, self.img_size[0] / ori_w\n","\n","        scaled_leftUp = (int(leftUp[0] * scale_width), int(leftUp[1] * scale_height))\n","        scaled_rightDown = (int(rightDown[0] * scale_width), int(rightDown[1] * scale_height))\n","\n","        # All four values of leftUp and rightDown scaled in 1 vector\n","        scaled_labels = (scaled_leftUp, scaled_rightDown)\n","        # scaled_labels = [int(leftUp[0] * scale_x, leftUp[1] * scale_y), (rightDown[0] * scale_x, rightDown[1] * scale_y)]\n","\n","        # Flatten scaled_labels into a 1D list\n","        flattened_labels = [coordinate for point in scaled_labels for coordinate in point]\n","\n","        # Convert the 1D list to a tensor and reshape it to (1, 4)\n","        scaled_labels_tensor = torch.tensor(flattened_labels, dtype=torch.float32)\n","\n","\n","        return resizedImage, scaled_labels_tensor, img_name\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699290744372,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"xW--T__29pGG","outputId":"723123b4-a256-4092-9082-860fec832608"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of dataset: 1605\n","Image shape: (224, 224, 3)\n","Labels: tensor([ 49.,  86., 168., 106.])\n","Image name: /content/gdrive/MyDrive/license_plate/data/04-90_267-158&448_542&553-541&553_162&551_158&448_542&450-0_1_3_24_27_33_30_24-99-116.jpg\n","Item retrieval successful.\n","got out here\n"]}],"source":["# Initialize your dataset\n","img_dir = [data_path]  # Replace with actual paths to your image directories\n","img_size = (224, 224)  # Replace with your desired image size\n","dataset = labelFpsDataLoader(img_dir=img_dir, imgSize=img_size)\n","\n","# Test the length of the dataset\n","print(f\"Length of dataset: {len(dataset)}\")\n","\n","# Test getting an item\n","try:\n","    # Retrieve the first item\n","    img, labels, img_name = dataset[0]\n","\n","    # Check the shapes and types\n","    print(f\"Image shape: {img.shape}\")\n","    print(f\"Labels: {labels}\")\n","    print(f\"Image name: {img_name}\")\n","\n","    # If the code reaches this point, the item has been retrieved successfully\n","    print(\"Item retrieval successful.\")\n","except Exception as e:\n","    # If there is any error, print it out\n","    print(f\"An error occurred: {e}\")\n","print(\"got out here\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJ_NSb9iP0Rj"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_img_and_boundingbox(image, labels):\n","    numpy_array = image.cpu().detach().numpy()\n","\n","    cv2_image = cv2.cvtColor(numpy_array, cv2.COLOR_RGB2BGR)\n","\n","    # Extract numerical values from tensors and convert to integers\n","    leftUp = (int(labels[0]),int(labels[1]))\n","    rightDown = (int(labels[2]),int(labels[3]))\n","    # Draw rectangle on the image\n","    new_image = cv2.rectangle(cv2_image, leftUp, rightDown, (255, 0, 0), 2)\n","\n","    # Display the image\n","    plt.imshow(new_image)\n","    plt.show()\n","\n","# scaled_labels = batch[1][0]\n","# plot_img_and_boundingbox(image, scaled_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":669,"status":"ok","timestamp":1699290324520,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"Akmn3oBa9pGI","outputId":"e7350baf-76ab-4e67-d26d-1592c4549762"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}],"source":["# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n","# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n","# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n","net = nn.Sequential(\n","    nn.Linear(960, 100),\n","    nn.ReLU(),\n","    nn.Dropout(0.01),\n","    nn.Linear(100, out_features=4, bias=True),\n",")\n","model.classifier = net\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhpB5DL-T0gw"},"outputs":[],"source":["# net = nn.Sequential(\n","#     nn.Linear(1280, 1024),\n","#     nn.ReLU(),\n","#     nn.Dropout(0.5),\n","#     nn.ReLU(),\n","#     nn.Linear(1024, out_features=4, bias=True),\n","# )\n","net = nn.Sequential(\n","    nn.Linear(960, 100),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.BatchNorm1d(100),\n","    nn.Linear(100, out_features=4, bias=True),\n",")\n","model.classifier = net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1699290325342,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"dyV_mS58Uyay","outputId":"d5eec382-f763-4d9c-fe2b-b14da850b8cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MobileNetV3(\n","  (features): Sequential(\n","    (0): ConvBNActivation(\n","      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","    (1): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): ConvBNActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (block): Sequential(\n","        (0): ConvBNActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): ConvBNActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (relu): ReLU(inplace=True)\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): ConvBNActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Identity()\n","        )\n","      )\n","    )\n","    (16): ConvBNActivation(\n","      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=1)\n","  (classifier): Sequential(\n","    (0): Linear(in_features=960, out_features=100, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=100, out_features=4, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":8}],"source":["#Sets model to training mode,e this is important for layers that have different functionalities depending on training or eval. for example BatchNorm\n","model.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1699290325342,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"},"user_tz":-60},"id":"1SB-5KBQXiej","outputId":"62a7f3b5-8d4f-481b-b3e8-3f373ac18d84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of layers is 176\n","Number of pretrained base layers is 172\n"]}],"source":["layers_of_classifier = 4\n","for i, param in enumerate(model.parameters()):\n","    if i < len(list(model.parameters())) - layers_of_classifier:\n","        param.requires_grad = False\n","    else:\n","        param.requires_grad = True\n","\n","number_of_layers = len(list(enumerate(model.parameters())))\n","print(f\"Total number of layers is {number_of_layers}\")\n","print(f\"Number of pretrained base layers is {number_of_layers - layers_of_classifier}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsf8PJ72ZFgy"},"outputs":[],"source":["def check_requires_grad():\n","  for name, param in model.named_parameters(): # Just to check\n","    if name.startswith('classifier'):\n","        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n","    if name.startswith('features'):\n","        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# check_requires_grad()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTwomuz6N5Po"},"outputs":[],"source":["from datetime import datetime\n","def bb_intersection_over_union(boxA, boxB): # https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n","\t# determine the (x, y)-coordinates of the intersection rectangle\n","\txA = max(boxA[0], boxB[0])\n","\tyA = max(boxA[1], boxB[1])\n","\txB = min(boxA[2], boxB[2])\n","\tyB = min(boxA[3], boxB[3])\n","\t# compute the area of intersection rectangle\n","\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\t# compute the area of both the prediction and ground-truth\n","\t# rectangles\n","\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","\t# compute the intersection over union by taking the intersection\n","\t# area and dividing it by the sum of prediction + ground-truth\n","\t# areas - the interesection area\n","\tiou = interArea / float(boxAArea + boxBArea - interArea)\n","\t# return the intersection over union value\n","\treturn iou\n","\n","def calculate_true_positives_in_batch(y_pred, y_batch):\n","  threshold = 0.5\n","  true_positive_amount = 0\n","  for i in range(y_pred.shape[0]):\n","    y_pred_numpy = y_pred[i].cpu().detach().numpy()\n","    y_batch_numpy = y_batch[i].cpu().detach().numpy()\n","    iou = bb_intersection_over_union(y_pred_numpy, y_batch_numpy)\n","    if iou > threshold:\n","      true_positive_amount +=1\n","  return true_positive_amount\n","\n","#wrapper of tqdm to enable toggling it off easily\n","def toggle_tqdm(iterable, use_tqdm=True):\n","  if use_tqdm:\n","    return tqdm(iterable)\n","  else:\n","    return iterable\n","\n","def calculate_loss_and_accuracy(loader):\n","  total_loss = 0\n","  total_true_positives = 0\n","  total_samples = 0\n","\n","  for X_batch_, y_batch, img_name in loader:\n","      X_batch = X_batch_.permute(0,3,1,2).to(device)\n","      y_batch = y_batch.to(device)\n","      y_pred = model(X_batch)\n","\n","      total_true_positives += calculate_true_positives_in_batch(y_pred, y_batch)\n","\n","      loss = loss_fn(y_pred, y_batch)\n","      total_loss += loss.item() * len(y_batch)  # Accumulate scaled loss\n","      total_samples += len(y_batch)  # Accumulate number of samples\n","  sample_loss = total_loss / total_samples  # Calculate average loss\n","  accuracy = total_true_positives / total_samples\n","  return sample_loss, accuracy\n","\n","def save_model(model):\n","  # Get the current time\n","  current_time = datetime.now()\n","\n","  # Format the time in a 'YearMonthDay_HourMinuteSecond' format for the filename\n","  timestamp = current_time.strftime('%Y%m%d_%H%M')\n","  model_path = f'/content/gdrive/MyDrive/license_plate/models/model_weights_{timestamp}.pth'\n","  torch.save(model.state_dict(), model_path)\n","\n","def load_model(path):\n","  model.load_state_dict(torch.load(path))\n"]},{"cell_type":"code","source":["# load_model('/content/gdrive/MyDrive/license_plate/models/model_weights_20231106_1410.pth')\n"],"metadata":{"id":"15nRrjd3_KGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595,"referenced_widgets":["fc7714303330448eb3d75afc5c4bd4f0","bc08c7836a2f43cb9fa0ced343f67dbd","9ec8fb61a04c44c891f8621e16c23394","132cb76d81484b10a012c3dc316b0acc","96b85257e65f4b05a9665fe36059583b","95fd007e2b6b4b82a44293a195baf7e9","c7131d9fbde24ac3852a12431ae46019","5ac5a15ce1954521873567768bfa4229","7a3d3f1d9638402482cc8817a5504b8b","d402d4a540b34ed294b9c1fdcd43f452","6a8687614612458f8e0e23bf0e47de4f"]},"id":"I2mUI6H5Arru","outputId":"332b64b7-396f-48ac-a979-922ea4e33168","executionInfo":{"status":"error","timestamp":1699290699726,"user_tz":-60,"elapsed":12148,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["using device:  cuda\n","Running on subset!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc7714303330448eb3d75afc5c4bd4f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1, Out-sample Loss: 128115.9937, Out-sample accuracy : 0.0000\n","Epoch 1, In-sample Loss: 128797.8598, In-sample Accuracy: 0.0000\n","Epoch 11, Out-sample Loss: 892.4036, Out-sample accuracy : 0.1000\n","Epoch 11, In-sample Loss: 1283.3981, In-sample Accuracy: 0.0795\n","Epoch 21, Out-sample Loss: 877.2515, Out-sample accuracy : 0.0800\n","Epoch 21, In-sample Loss: 1214.2494, In-sample Accuracy: 0.0734\n","Epoch 31, Out-sample Loss: 913.9891, Out-sample accuracy : 0.0800\n","Epoch 31, In-sample Loss: 1194.7322, In-sample Accuracy: 0.0703\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-76d375b729b0>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Train decoder (initial)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DECODER TRAINING DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-76d375b729b0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(n_epochs, optimizer, scheduler, dataloader, validation_loader)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoggle_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# print(\"epoch:\", i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoggle_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Needs to have shape [batch_size, channels, height, width]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["scaler = torch.cuda.amp.GradScaler()\n","\n","# Determine hardware\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"using device: \", device)\n","\n","# Define dataloader for training\n","data_loader = labelFpsDataLoader([data_path],(500,1000))\n","train_loader = DataLoader(data_loader, batch_size=16, shuffle=True, num_workers=2)\n","\n","test_loader = labelFpsDataLoader([test_path],(500,1000))\n","validation_loader = DataLoader(test_loader, batch_size=64, shuffle=True, num_workers=2)\n","# Determine subset?? (mabeto??)\n","subset = not is_running_on_colab\n","subset = True\n","subset_data = Subset(data_loader, indices=range(327))\n","subset_val = Subset(test_loader, indices=range(100))\n","if subset:\n","  print(\"Running on subset!\")\n","  train_loader =DataLoader(subset_data, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","  train_loader_finetuning =DataLoader(subset_data, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n","  validation_loader = DataLoader(subset_val, batch_size=16, shuffle=True, num_workers=2)\n","\n","decoder_epochs = 50\n","n_epochs = 200\n","# dataiter = iter(trainloader)\n","# first_batch = next(dataiter)\n","\n","# # Now you can access the data and target tensors\n","# X_batch, y_batch, img_name = first_batch\n","\n","# print(X_batch.shape)\n","# Define dataloader for validation\n","\n","# Define model and hyperparameters\n","loss_fn = nn.MSELoss()\n","optimizer_decoder = optim.AdamW(model.parameters(), lr=0.001)\n","#We believe the scheduler LR overrules adam?\n","scheduler_decoder = optim.lr_scheduler.CyclicLR(optimizer_decoder,base_lr=0.01, max_lr=5, cycle_momentum=False)\n","\n","# scheduler_decoder = optim.lr_scheduler.OneCycleLR(optimizer_decoder, max_lr=0.01,total_steps=decoder_epochs)\n","\n","optimizer_full = optim.AdamW(model.parameters(), lr=0.00005)\n","# scheduler_full = optim.lr_scheduler.OneCycleLR(optimizer_decoder, max_lr=0.001,total_steps=n_epochs)\n","scheduler_full = optim.lr_scheduler.CyclicLR(optimizer_decoder,base_lr=0.0001, max_lr=0.1, cycle_momentum=False)\n","model.train()\n","model.to(device)\n","\n","use_tqdm = True\n","# Train\n","def train_model(n_epochs, optimizer, scheduler, dataloader,validation_loader):\n","  test_loss_history = []\n","  val_loss_history = []\n","  test_accuracy_history = []\n","  val_accuracy_history = []\n","  i = 0\n","  for epoch in toggle_tqdm(range(n_epochs), use_tqdm):\n","    # print(\"epoch:\", i)\n","    for X_batch, y_batch, img_name in toggle_tqdm(dataloader, False):\n","      optimizer.zero_grad()\n","      X_batch = X_batch.permute(0,3,1,2).to(device) # Needs to have shape [batch_size, channels, height, width]\n","      y_batch = y_batch.to(device)\n","      with torch.cuda.amp.autocast():\n","        y_pred = model(X_batch)\n","        loss = loss_fn(y_pred,y_batch)\n","      scaler.scale(loss).backward()\n","      scaler.step(optimizer)\n","      scaler.update()\n","      # loss.backward()\n","      # optimizer.step()\n","    scheduler.step()\n","    # In-sample & out-sample loss calculation\n","    model.eval()  # Switch to evaluation mode to disable features like dropout\n","    #time the following\n","\n","    if epoch % 10 == 0:\n","      with torch.no_grad():  # Disable gradient calculation to save memory\n","          # In sample\n","          in_sample_loss, in_sample_accuracy = calculate_loss_and_accuracy(dataloader)\n","          test_loss_history.append(in_sample_loss)\n","          test_accuracy_history.append(in_sample_accuracy)\n","          # print(f'Epoch {epoch+1}, In-sample Loss : {in_sample_loss:.4f}, In-sample accuracy : {in_sample_accuracy:.4f}' )\n","\n","          # Out sample\n","          out_sample_loss, out_sample_accuracy = calculate_loss_and_accuracy(validation_loader)\n","          val_loss_history.append(out_sample_loss)\n","          val_accuracy_history.append(out_sample_accuracy)\n","          tqdm.write(f'Epoch {epoch+1}, Out-sample Loss: {out_sample_loss:.4f}, Out-sample accuracy : {out_sample_accuracy:.4f}')\n","          tqdm.write(f'Epoch {epoch+1}, In-sample Loss: {in_sample_loss:.4f}, In-sample Accuracy: {in_sample_accuracy:.4f}')\n","    i += 1\n","\n","  return test_loss_history, val_loss_history, test_accuracy_history, val_accuracy_history\n","\n","# Train decoder (initial)\n","train_model(decoder_epochs, optimizer_decoder, scheduler_decoder,train_loader, validation_loader)\n","save_model(model)\n","print(\"DECODER TRAINING DONE\")\n","# Unfreeze encoder\n","for i, param in enumerate(model.parameters()):\n","  param.requires_grad = True\n","\n","# Train encoder\n","test_loss_history, val_loss_history, test_accuracy_history, val_accuracy_history = train_model(n_epochs, optimizer_full, scheduler_full,train_loader_finetuning, validation_loader)\n","\n","\n","\n"]},{"cell_type":"code","source":["save_model(model)\n"],"metadata":{"id":"pkuxBNA391kU","executionInfo":{"status":"aborted","timestamp":1699290699730,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initial_lr = 0.00001\n","# lr_epochs = 100\n","# optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n","\n","\n","# lr_hist = []\n","# train_loss_history = []\n","\n","# def train_model(n_epochs):\n","#   i = 0\n","#   lr = initial_lr\n","#   for epoch in toggle_tqdm(range(n_epochs), use_tqdm):\n","#     # print(\"epoch:\", i)\n","#     for X_batch, y_batch, img_name in toggle_tqdm(trainloader, False):\n","#       agg_loss = 0\n","#       X_batch = X_batch.permute(0,3,1,2).to(device) # Needs to have shape [batch_size, channels, height, width]\n","#       y_batch = y_batch.to(device)\n","#       y_pred = model(X_batch)\n","#       loss = loss_fn(y_pred,y_batch)\n","#       optimizer.zero_grad()\n","#       loss.backward()\n","#       optimizer.step()\n","#       agg_loss += loss.item()\n","#       train_loss_history.append(agg_loss)\n","\n","#       lr_hist.append(lr)\n","\n","#       lr = 1.1*lr\n","#       for g in optimizer.param_groups:\n","#         g['lr'] = lr\n","#       if lr >= 0.0005:\n","#         break\n","\n","# train_model(3)\n","\n","\n"],"metadata":{"id":"lD97FfcQlN5t","executionInfo":{"status":"aborted","timestamp":1699290699731,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 5))\n","plt.xscale('log')  # Set the y-axis to a logarithmic scale\n","\n","plt.plot(lr_hist,train_loss_history, label='Train Loss')\n","plt.xlabel('LR')\n","plt.ylabel('Loss')\n","plt.grid(True)\n","plt.legend()  # Add a legend to differentiate between train and validation loss\n","plt.show()\n","print(train_loss_history)\n","print(lr_hist)"],"metadata":{"id":"C64tHl3KjUQW","executionInfo":{"status":"aborted","timestamp":1699290699731,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zK6lBjlVEUyX","executionInfo":{"status":"aborted","timestamp":1699290699732,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","#plt.yscale('log')  # Set the y-axis to a logarithmic scale\n","plt.plot(test_loss_history, label='Train Loss')\n","plt.plot(val_loss_history, label='Validation Loss')\n","plt.title('Loss Curve')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid(True)\n","plt.legend()  # Add a legend to differentiate between train and validation loss\n","plt.show()\n","print(val_accuracy_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H8s5ea1LC82K","executionInfo":{"status":"aborted","timestamp":1699290699732,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[],"source":["#print a trainset with predicted label\n","# train_loader = DataLoader(data_loader, batch_size=1, shuffle=True, num_workers=1)\n","\n","train_iter = iter(train_loader)\n","\n","batch = next(train_iter)\n","\n","X_batch, y_batch, _ = batch\n","print(X_batch.shape)\n","print(y_batch.shape)\n","\n","image = batch[0][0]\n","labels = batch[1][0]\n","\n","# Get predicted labels\n","X_batch = X_batch.permute(0,3,1,2).to(device)\n","print(X_batch.shape)\n","pred = model(X_batch)\n","\n","plot_img_and_boundingbox(image, labels)\n","plot_img_and_boundingbox(image, pred[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RyFhpzW1OwKe","executionInfo":{"status":"aborted","timestamp":1699290699733,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[],"source":["# Print a validation image with its predicted labels\n","\n","validationloader = DataLoader(test_loader, batch_size=1, shuffle=True, num_workers=1)\n","\n","validationloader_iter = iter(validationloader)\n","\n","batch = next(validationloader_iter)\n","\n","X_batch, y_batch, _ = batch\n","print(X_batch.shape)\n","print(y_batch.shape)\n","\n","image = batch[0][0]\n","labels = batch[1][0]\n","\n","# Get predicted labels\n","X_batch = X_batch.permute(0,3,1,2).to(device)\n","print(X_batch.shape)\n","pred = model(X_batch)\n","\n","plot_img_and_boundingbox(image, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytHrhFV8aX-C","executionInfo":{"status":"aborted","timestamp":1699290699733,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[],"source":["plot_img_and_boundingbox(image,pred[0])\n","print(pred)\n","print(calculate_true_positives_in_batch(labels.view(1,4),pred[0].view(1,4))) # Need to change view since we dont have batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghHYl7RzIXDF","executionInfo":{"status":"aborted","timestamp":1699290699733,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mads Toftrup","userId":"13128254388410215024"}}},"outputs":[],"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/mabeto5p/License_plate/blob/mads_working_branch/license_plate_bounding.ipynb","timestamp":1699028930209}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fc7714303330448eb3d75afc5c4bd4f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc08c7836a2f43cb9fa0ced343f67dbd","IPY_MODEL_9ec8fb61a04c44c891f8621e16c23394","IPY_MODEL_132cb76d81484b10a012c3dc316b0acc"],"layout":"IPY_MODEL_96b85257e65f4b05a9665fe36059583b"}},"bc08c7836a2f43cb9fa0ced343f67dbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95fd007e2b6b4b82a44293a195baf7e9","placeholder":"​","style":"IPY_MODEL_c7131d9fbde24ac3852a12431ae46019","value":" 74%"}},"9ec8fb61a04c44c891f8621e16c23394":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac5a15ce1954521873567768bfa4229","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a3d3f1d9638402482cc8817a5504b8b","value":37}},"132cb76d81484b10a012c3dc316b0acc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d402d4a540b34ed294b9c1fdcd43f452","placeholder":"​","style":"IPY_MODEL_6a8687614612458f8e0e23bf0e47de4f","value":" 37/50 [06:08&lt;02:02,  9.43s/it]"}},"96b85257e65f4b05a9665fe36059583b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95fd007e2b6b4b82a44293a195baf7e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7131d9fbde24ac3852a12431ae46019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ac5a15ce1954521873567768bfa4229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a3d3f1d9638402482cc8817a5504b8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d402d4a540b34ed294b9c1fdcd43f452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8687614612458f8e0e23bf0e47de4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}