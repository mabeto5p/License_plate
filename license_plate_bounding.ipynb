{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L3Bt81myNxC",
        "outputId": "7fe444a9-941a-4324-88cc-81b5cdef381d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# External libraries used for various tasks in later parts of the code\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from torch.utils.data import Dataset\n",
        "from imutils import paths\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "# Check if running on Google Colab and set the data paths accordingly\n",
        "is_running_on_colab = 'COLAB_GPU' in os.environ\n",
        "if is_running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    data_path = '/content/gdrive/MyDrive/license_plate/data/'\n",
        "    test_path = '/content/gdrive/MyDrive/license_plate/testdata/'\n",
        "else:\n",
        "    current_dir = os.getcwd()\n",
        "    data_path = os.path.join(current_dir, 'dataset', 'license_plate', 'data')\n",
        "    test_path = os.path.join(current_dir, 'dataset', 'license_plate', 'test_data')\n",
        "\n",
        "# Function to check if directories exist\n",
        "def check_directories_exist(*paths):\n",
        "    for path in paths:\n",
        "        assert os.path.isdir(path), f\"The directory {path} does not exist.\"\n",
        "\n",
        "# Check the directories\n",
        "check_directories_exist(data_path, test_path)\n",
        "\n",
        "data_link = \"https://drive.google.com/open?id=1rdEsCUcIUaYOVRkx5IMTRNA7PcGMmSgc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8KmlcMPjCpiI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import os\n",
        "import torch\n",
        "\n",
        "class LabelFpsDataLoader(Dataset):\n",
        "    def __init__(self, img_dirs, img_size, is_transform=None):\n",
        "        self.img_paths = [p for img_dir in img_dirs for p in paths.list_images(img_dir)]\n",
        "        self.img_size = img_size\n",
        "        self.is_transform = is_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.img_paths[index]\n",
        "        img = cv2.imread(img_name)\n",
        "        resized_image = self.transform_image(img)\n",
        "\n",
        "        file_name = os.path.splitext(os.path.basename(img_name))[0]\n",
        "        labels = self.extract_labels(file_name, img.shape)\n",
        "\n",
        "        return resized_image, labels, img_name\n",
        "\n",
        "    def transform_image(self, img):\n",
        "        resized_image = cv2.resize(img, self.img_size).astype('float32') / 255.0\n",
        "        # print(resized_image.dtype)\n",
        "        # Normalization - Adjust mean and std if necessary\n",
        "        mean = np.array([0.485, 0.456, 0.406], dtype=resized_image.dtype)\n",
        "        std = np.array([0.229, 0.224, 0.225],dtype=resized_image.dtype)\n",
        "\n",
        "        resized_image = (resized_image - mean) / std  # Normalize\n",
        "        # print(resized_image.dtype)\n",
        "        return resized_image\n",
        "\n",
        "    def extract_labels(self, file_name, img_shape):\n",
        "        parts = file_name.split('-')\n",
        "        points = [self.parse_point(part) for part in parts[2].split('_')]\n",
        "        ori_w, ori_h = img_shape[1], img_shape[0]\n",
        "        scale_w, scale_h = self.img_size[0] / ori_w, self.img_size[1] / ori_h\n",
        "        scaled_points = [(int(x * scale_w), int(y * scale_h)) for x, y in points]\n",
        "        flattened_labels = [coord for point in scaled_points for coord in point]\n",
        "        return torch.tensor(flattened_labels, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_point(point_str):\n",
        "        return tuple(int(coord) for coord in point_str.split('&'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW--T__29pGG",
        "outputId": "04dee80e-942d-46e6-a2ca-b3935f0f3568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset: 5769\n",
            "An error occurred: name 'np' is not defined\n",
            "Got out here\n"
          ]
        }
      ],
      "source": [
        "# Initialize your dataset\n",
        "img_dirs = [data_path]  # Replace with actual paths to your image directories\n",
        "img_size = (224, 224)  # Replace with your desired image size\n",
        "dataset = LabelFpsDataLoader(img_dirs=img_dirs, img_size=img_size)  # Use 'img_dirs' as the correct argument name\n",
        "\n",
        "# Test the length of the dataset\n",
        "print(f\"Length of dataset: {len(dataset)}\")\n",
        "#\n",
        "# Test getting an item\n",
        "try:\n",
        "    # Retrieve the first item\n",
        "    img, labels, img_name = dataset[0]\n",
        "\n",
        "    # Check the shapes and types\n",
        "    print(f\"Image shape: {img.shape}\")\n",
        "    print(f\"Labels: {labels}\")\n",
        "    print(f\"Image name: {img_name}\")\n",
        "\n",
        "    # If the code reaches this point, the item has been retrieved successfully\n",
        "    print(\"Item retrieval successful.\")\n",
        "except Exception as e:\n",
        "    # If there is any error, print it out\n",
        "    print(f\"An error occurred: {e}\")\n",
        "finally:\n",
        "    print(\"Got out here\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AJ_NSb9iP0Rj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_img_and_boundingbox(image, labels):\n",
        "    # Assuming image is a PyTorch tensor, we need to first move it to CPU if it's on GPU,\n",
        "    # then detach it from the current graph, convert to numpy, and finally transpose it\n",
        "    # from (channels, height, width) to (height, width, channels)\n",
        "    numpy_array = image.cpu().detach().numpy()\n",
        "\n",
        "    # Convert from BGR to RGB format if the image was read by OpenCV\n",
        "    rgb_image = cv2.cvtColor(numpy_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Extract numerical values from tensors and convert to integers\n",
        "    left_up = (int(labels[0]), int(labels[1]))\n",
        "    right_down = (int(labels[2]), int(labels[3]))\n",
        "\n",
        "    # Draw rectangle on the image\n",
        "    new_image = cv2.rectangle(rgb_image, left_up, right_down, (255, 0, 0), 2)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(new_image)\n",
        "    plt.axis('off')  # Hide the axis\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# img, labels, _ = dataset[0]  # Assuming this is how you get an image and labels from your dataset\n",
        "# plot_img_and_boundingbox(img, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akmn3oBa9pGI",
        "outputId": "30a13ad1-440c-45aa-b477-afd3a816b204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 82.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV3(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNActivation(\n",
              "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): ConvBNActivation(\n",
              "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (block): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Hardswish()\n",
              "        )\n",
              "        (2): SqueezeExcitation(\n",
              "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): ConvBNActivation(\n",
              "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "          (2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (16): ConvBNActivation(\n",
              "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
              "      (2): Hardswish()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=960, out_features=100, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.0, inplace=False)\n",
              "    (3): Linear(in_features=100, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Function to create the modified classifier\n",
        "def create_custom_classifier(input_features, hidden_units, output_features):\n",
        "    classifier = nn.Sequential(\n",
        "        nn.Linear(input_features, hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.0),\n",
        "        #nn.BatchNorm1d(hidden_units),\n",
        "        nn.Linear(hidden_units, output_features),\n",
        "    )\n",
        "    return classifier\n",
        "\n",
        "# Load a pre-trained MobileNetV3 model\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n",
        "\n",
        "# Replace the classifier with a new one - adjust the input_features to match the last layer of MobileNetV3\n",
        "model.classifier = create_custom_classifier(input_features=960, hidden_units=100, output_features=4)\n",
        "#Sets model to training mode,e this is important for layers that have different functionalities depending on training or eval. for example BatchNorm\n",
        "model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SB-5KBQXiej",
        "outputId": "245b9ce0-1153-443e-ea3e-8cd6d81dc9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of layers is 174\n",
            "Number of pretrained base layers is 170\n"
          ]
        }
      ],
      "source": [
        "# Number of layers you want to fine-tune\n",
        "layers_of_classifier = len(model.classifier)\n",
        "\n",
        "# Get all the parameters from the model as a list\n",
        "parameters = list(model.parameters())\n",
        "\n",
        "# The total number of layers is the length of the parameters list\n",
        "number_of_layers = len(parameters)\n",
        "print(f\"Total number of layers is {number_of_layers}\")\n",
        "\n",
        "# Calculate the number of pretrained layers (all except the last 'layers_of_classifier')\n",
        "pretrained_layers = number_of_layers - layers_of_classifier\n",
        "print(f\"Number of pretrained base layers is {pretrained_layers}\")\n",
        "\n",
        "# Freeze the parameters of the pretrained base layers\n",
        "for param in parameters[:-layers_of_classifier]:\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the parameters of the last 'layers_of_classifier' layers\n",
        "for param in parameters[-layers_of_classifier:]:\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qsf8PJ72ZFgy"
      },
      "outputs": [],
      "source": [
        "def check_requires_grad():\n",
        "  for name, param in model.named_parameters(): # Just to check\n",
        "    if name.startswith('classifier'):\n",
        "        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n",
        "    if name.startswith('features'):\n",
        "        print(f'Layer {name} - requires_grad: {param.requires_grad}')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# check_requires_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LTwomuz6N5Po"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "# def bb_intersection_over_union(boxA, boxB): # https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
        "# \t# determine the (x, y)-coordinates of the intersection rectangle\n",
        "# \txA = max(boxA[0], boxB[0])\n",
        "# \tyA = max(boxA[1], boxB[1])\n",
        "# \txB = min(boxA[2], boxB[2])\n",
        "# \tyB = min(boxA[3], boxB[3])\n",
        "# \t# compute the area of intersection rectangle\n",
        "# \tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "# \t# compute the area of both the prediction and ground-truth\n",
        "# \t# rectangles\n",
        "# \tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "# \tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "# \t# compute the intersection over union by taking the intersection\n",
        "# \t# area and dividing it by the sum of prediction + ground-truth\n",
        "# \t# areas - the interesection area\n",
        "# \tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "# \t# return the intersection over union value\n",
        "# \treturn iou\n",
        "\n",
        "# def calculate_true_positives_in_batch(y_pred, y_batch):\n",
        "#   threshold = 0.5\n",
        "#   true_positive_amount = 0\n",
        "#   for i in range(y_pred.shape[0]):\n",
        "#     y_pred_numpy = y_pred[i].cpu().detach().numpy()\n",
        "#     y_batch_numpy = y_batch[i].cpu().detach().numpy()\n",
        "#     iou = bb_intersection_over_union(y_pred_numpy, y_batch_numpy)\n",
        "#     if iou > threshold:\n",
        "#       true_positive_amount +=1\n",
        "#   return true_positive_amount\n",
        "\n",
        "# #wrapper of tqdm to enable toggling it off easily\n",
        "# def toggle_tqdm(iterable, use_tqdm=True):\n",
        "#   if use_tqdm:\n",
        "#     return tqdm(iterable)\n",
        "#   else:\n",
        "#     return iterable\n",
        "\n",
        "# def calculate_loss_and_accuracy(loader):\n",
        "#   total_loss = 0\n",
        "#   total_true_positives = 0\n",
        "#   total_samples = 0\n",
        "\n",
        "#   for X_batch_, y_batch, img_name in loader:\n",
        "#       X_batch = X_batch_.permute(0,3,1,2).to(device)\n",
        "#       y_batch = y_batch.to(device)\n",
        "#       y_pred = model(X_batch)\n",
        "\n",
        "#       total_true_positives += calculate_true_positives_in_batch(y_pred, y_batch)\n",
        "\n",
        "#       loss = loss_fn(y_pred, y_batch)\n",
        "#       total_loss += loss.item() * len(y_batch)  # Accumulate scaled loss\n",
        "#       total_samples += len(y_batch)  # Accumulate number of samples\n",
        "#   sample_loss = total_loss / total_samples  # Calculate average loss\n",
        "#   accuracy = total_true_positives / total_samples\n",
        "#   return sample_loss, accuracy\n",
        "\n",
        "# def save_model(model):\n",
        "#   # Get the current time\n",
        "#   current_time = datetime.now()\n",
        "\n",
        "#   # Format the time in a 'YearMonthDay_HourMinuteSecond' format for the filename\n",
        "#   timestamp = current_time.strftime('%Y%m%d_%H%M')\n",
        "#   model_path = f'/content/gdrive/MyDrive/license_plate/models/model_weights_{timestamp}.pth'\n",
        "#   torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# def load_model(path):\n",
        "#   model.load_state_dict(torch.load(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model):\n",
        "  # Get the current time\n",
        "  current_time = datetime.now()\n",
        "\n",
        "  # Format the time in a 'YearMonthDay_HourMinuteSecond' format for the filename\n",
        "  timestamp = current_time.strftime('%Y%m%d_%H%M')\n",
        "  model_path = f'/content/gdrive/MyDrive/license_plate/models/model_weights_{timestamp}.pth'\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "\n",
        "def load_model(path):\n",
        "  model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "fAs1fLmwTcCy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bb_intersection_over_union(boxA, boxB):\n",
        "    # Compute the intersection over union on GPU\n",
        "    # Assumes boxA and boxB are tensors\n",
        "    xA = torch.max(boxA[..., 0], boxB[..., 0])\n",
        "    yA = torch.max(boxA[..., 1], boxB[..., 1])\n",
        "    xB = torch.min(boxA[..., 2], boxB[..., 2])\n",
        "    yB = torch.min(boxA[..., 3], boxB[..., 3])\n",
        "\n",
        "    interArea = torch.clamp(xB - xA, min=0) * torch.clamp(yB - yA, min=0)\n",
        "\n",
        "    boxAArea = (boxA[..., 2] - boxA[..., 0]) * (boxA[..., 3] - boxA[..., 1])\n",
        "    boxBArea = (boxB[..., 2] - boxB[..., 0]) * (boxB[..., 3] - boxB[..., 1])\n",
        "\n",
        "    iou = interArea / (boxAArea + boxBArea - interArea)\n",
        "    return iou\n",
        "\n",
        "def calculate_true_positives_in_batch(y_pred, y_batch, threshold=0.5):\n",
        "    # Calculate IoU for the batch\n",
        "    iou = bb_intersection_over_union(y_pred, y_batch)\n",
        "\n",
        "    # Count true positives in the batch\n",
        "    true_positives = torch.sum(iou > threshold).item()\n",
        "    return true_positives\n",
        "\n",
        "def calculate_loss_and_accuracy(loader, model, loss_fn, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total_true_positives = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for X_batch, y_batch, _ in loader:\n",
        "            X_batch = X_batch.permute(0,3,1,2).to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "\n",
        "            total_true_positives += calculate_true_positives_in_batch(y_pred, y_batch)\n",
        "\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            total_loss += loss.item() * X_batch.size(0)  # Accumulate scaled loss\n",
        "            total_samples += X_batch.size(0)  # Accumulate number of samples\n",
        "\n",
        "    sample_loss = total_loss / total_samples  # Calculate average loss\n",
        "    accuracy = total_true_positives / total_samples  # Calculate accuracy\n",
        "    return sample_loss, accuracy\n"
      ],
      "metadata": {
        "id": "2QRQ0qnbND9t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load_model('/content/gdrive/MyDrive/license_plate/models/model_weights_20231106_1410.pth')\n"
      ],
      "metadata": {
        "id": "15nRrjd3_KGM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I2mUI6H5Arru"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Constants\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_PATH = [data_path]\n",
        "TEST_PATH = [test_path]\n",
        "BATCH_SIZE = 2\n",
        "VAL_BATCH_SIZE = 2\n",
        "SUBSET_INDICES = 16\n",
        "SUBSET_VAL_INDICES = 16\n",
        "DECODER_EPOCHS = 50\n",
        "N_EPOCHS = 100\n",
        "USE_TQDM = True\n",
        "USE_SUBSET = True\n",
        "PRINT_EVERY = 5\n",
        "\n",
        "# Define model, loss function, optimizers, and schedulers\n",
        "model.to(DEVICE)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer_decoder = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "# scheduler_decoder = optim.lr_scheduler.OneCycleLR(optimizer_decoder, 1e-2, total_steps=DECODER_EPOCHS)\n",
        "scheduler_decoder = optim.lr_scheduler.CyclicLR(optimizer_decoder, base_lr=1e-5, max_lr=1e-3, cycle_momentum=False, step_size_up=DECODER_EPOCHS/6)\n",
        "optimizer_full = optim.AdamW(model.parameters(), lr=5e-6)\n",
        "scheduler_full = optim.lr_scheduler.CyclicLR(optimizer_decoder, base_lr=1e-5, max_lr=1e-4, cycle_momentum=False, step_size_up=N_EPOCHS/6)\n",
        "\n",
        "# Define dataloaders\n",
        "train_dataset = LabelFpsDataLoader(DATA_PATH, (500, 1000))\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_dataset = LabelFpsDataLoader(TEST_PATH, (500, 1000))\n",
        "validation_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# Use subsets for faster iterations during development\n",
        "if USE_SUBSET:\n",
        "    train_dataset = Subset(train_dataset, indices=range(SUBSET_INDICES))\n",
        "    val_dataset = Subset(val_dataset, indices=range(SUBSET_VAL_INDICES))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    validation_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# Training functions\n",
        "def train_epoch(dataloader, optimizer, model, loss_fn, scaler):\n",
        "    for X_batch, y_batch, _ in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        X_batch = X_batch.permute(0, 3, 1, 2).to(DEVICE)\n",
        "        y_batch = y_batch.to(DEVICE)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "def train_model(n_epochs, optimizer, scheduler, dataloader, val_loader, model, loss_fn):\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    train_accuracy_history = []\n",
        "    val_accuracy_history = []\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        model.train()\n",
        "        # print(f\"epoch: {epoch}\")\n",
        "        train_epoch(dataloader, optimizer, model, loss_fn, scaler)\n",
        "        scheduler.step()\n",
        "\n",
        "        if epoch % PRINT_EVERY == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                # In-sample\n",
        "                in_sample_loss, in_sample_accuracy = calculate_loss_and_accuracy(dataloader, model, loss_fn, device)\n",
        "\n",
        "                train_loss_history.append(in_sample_loss)\n",
        "                train_accuracy_history.append(in_sample_accuracy)\n",
        "\n",
        "                # Out-sample\n",
        "                out_sample_loss, out_sample_accuracy = calculate_loss_and_accuracy(val_loader, model, loss_fn, device)\n",
        "                val_loss_history.append(out_sample_loss)\n",
        "                val_accuracy_history.append(out_sample_accuracy)\n",
        "\n",
        "                if USE_TQDM:\n",
        "                    tqdm.write(f'Epoch {epoch + 1}, In-sample Loss: {in_sample_loss:.4f}, In-sample Accuracy: {in_sample_accuracy:.4f}')\n",
        "                    tqdm.write(f'Epoch {epoch + 1}, Out-sample Loss: {out_sample_loss:.4f}, Out-sample Accuracy: {out_sample_accuracy:.4f}')\n",
        "\n",
        "    return train_loss_history, val_loss_history, train_accuracy_history, val_accuracy_history\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation functions are assumed to be defined above this script\n",
        "\n",
        "# Train the model with the decoder first\n",
        "print(\"Starting training with decoder...\")\n",
        "decoder_loss_history, decoder_val_loss_history, decoder_test_accuracy_history, decoder_val_accuracy_history = train_model(\n",
        "    n_epochs=DECODER_EPOCHS,\n",
        "    optimizer=optimizer_decoder,\n",
        "    scheduler=scheduler_decoder,\n",
        "    dataloader=train_loader,\n",
        "    val_loader=validation_loader,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn\n",
        ")\n",
        "save_model(model)\n",
        "# print(\"Decoder training completed.\")\n",
        "\n",
        "# Unfreeze model layers for full model training\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Now train the full model\n",
        "print(\"Starting full model training...\")\n",
        "full_loss_history, full_val_loss_history, full_test_accuracy_history, full_val_accuracy_history = train_model(\n",
        "    n_epochs=N_EPOCHS,\n",
        "    optimizer=optimizer_full,\n",
        "    scheduler=scheduler_full,\n",
        "    dataloader=train_loader,  # Assuming train_loader_finetuning is the same as train_loader\n",
        "    val_loader=validation_loader,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn\n",
        ")\n",
        "save_model(model)\n",
        "print(\"Full model training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQlYbSMiQc5K",
        "outputId": "29116d56-eff7-4a13-f787-cfe997131148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with decoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "  2%|▏         | 1/50 [00:22<18:23, 22.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, In-sample Loss: 121188.9854, In-sample Accuracy: 0.0000\n",
            "Epoch 1, Out-sample Loss: 124832.2090, Out-sample Accuracy: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 6/50 [01:01<07:17,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, In-sample Loss: 117071.3301, In-sample Accuracy: 0.0000\n",
            "Epoch 6, Out-sample Loss: 120483.7646, Out-sample Accuracy: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [01:06<06:06,  8.53s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_to_test = [(1e-4, 1e-2),(1e-5, 1e-3),(1e-6, 1e-4)]\n",
        "result_dict =\n",
        "for lr_base, lr_max in lr_to_test:\n",
        "  optimizer_decoder = optim.AdamW(model.parameters(), lr=lr_base)\n",
        "  # scheduler_decoder = optim.lr_scheduler.OneCycleLR(optimizer_decoder, 1e-2, total_steps=DECODER_EPOCHS)\n",
        "  scheduler_decoder = optim.lr_scheduler.CyclicLR(optimizer_decoder, base_lr=lr_base, max_lr=lr_max, cycle_momentum=False, step_size_up=DECODER_EPOCHS/6)\n",
        "  optimizer_full = optim.AdamW(model.parameters(), lr=5e-6)\n",
        "  scheduler_full = optim.lr_scheduler.CyclicLR(optimizer_decoder, base_lr=lr_base, max_lr=lr_max, cycle_momentum=False, step_size_up=N_EPOCHS/6)\n",
        "  decoder_loss_history, decoder_val_loss_history, decoder_test_accuracy_history, decoder_val_accuracy_history = train_model(\n",
        "    n_epochs=DECODER_EPOCHS,\n",
        "    optimizer=optimizer_decoder,\n",
        "    scheduler=scheduler_decoder,\n",
        "    dataloader=train_loader,\n",
        "    val_loader=validation_loader,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn\n",
        "  )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pkuxBNA391kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_lr = 0.00001\n",
        "# lr_epochs = 100\n",
        "# optimizer = optim.SGD(model.parameters(), lr=initial_lr)\n",
        "\n",
        "\n",
        "# lr_hist = []\n",
        "# train_loss_history = []\n",
        "\n",
        "# def train_model(n_epochs):\n",
        "#   i = 0\n",
        "#   lr = initial_lr\n",
        "#   for epoch in toggle_tqdm(range(n_epochs), use_tqdm):\n",
        "#     # print(\"epoch:\", i)\n",
        "#     for X_batch, y_batch, img_name in toggle_tqdm(trainloader, False):\n",
        "#       agg_loss = 0\n",
        "#       X_batch = X_batch.permute(0,3,1,2).to(device) # Needs to have shape [batch_size, channels, height, width]\n",
        "#       y_batch = y_batch.to(device)\n",
        "#       y_pred = model(X_batch)\n",
        "#       loss = loss_fn(y_pred,y_batch)\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "#       agg_loss += loss.item()\n",
        "#       train_loss_history.append(agg_loss)\n",
        "\n",
        "#       lr_hist.append(lr)\n",
        "\n",
        "#       lr = 1.1*lr\n",
        "#       for g in optimizer.param_groups:\n",
        "#         g['lr'] = lr\n",
        "#       if lr >= 0.0005:\n",
        "#         break\n",
        "\n",
        "# train_model(3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lD97FfcQlN5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.xscale('log')  # Set the y-axis to a logarithmic scale\n",
        "\n",
        "plt.plot(lr_hist,train_loss_history, label='Train Loss')\n",
        "plt.xlabel('LR')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()  # Add a legend to differentiate between train and validation loss\n",
        "plt.show()\n",
        "print(train_loss_history)\n",
        "print(lr_hist)"
      ],
      "metadata": {
        "id": "C64tHl3KjUQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK6lBjlVEUyX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "#plt.yscale('log')  # Set the y-axis to a logarithmic scale\n",
        "plt.plot(test_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()  # Add a legend to differentiate between train and validation loss\n",
        "plt.show()\n",
        "print(val_accuracy_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8s5ea1LC82K"
      },
      "outputs": [],
      "source": [
        "#print a trainset with predicted label\n",
        "# train_loader = DataLoader(data_loader, batch_size=1, shuffle=True, num_workers=1)\n",
        "\n",
        "train_iter = iter(train_loader)\n",
        "\n",
        "batch = next(train_iter)\n",
        "\n",
        "X_batch, y_batch, _ = batch\n",
        "\n",
        "image = batch[0][0]\n",
        "labels = batch[1][0]\n",
        "\n",
        "# Get predicted labels\n",
        "X_batch = X_batch.permute(0,3,1,2).to(device)\n",
        "pred = model(X_batch)\n",
        "print(image.shape)\n",
        "plot_img_and_boundingbox(image, labels)\n",
        "plot_img_and_boundingbox(image, pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyFhpzW1OwKe"
      },
      "outputs": [],
      "source": [
        "# Print a validation image with its predicted labels\n",
        "\n",
        "validationloader = DataLoader(test_loader, batch_size=1, shuffle=True, num_workers=1)\n",
        "\n",
        "validationloader_iter = iter(validationloader)\n",
        "\n",
        "batch = next(validationloader_iter)\n",
        "\n",
        "X_batch, y_batch, _ = batch\n",
        "print(X_batch.shape)\n",
        "print(y_batch.shape)\n",
        "\n",
        "image = batch[0][0]\n",
        "labels = batch[1][0]\n",
        "\n",
        "# Get predicted labels\n",
        "X_batch = X_batch.permute(0,3,1,2).to(device)\n",
        "print(X_batch.shape)\n",
        "pred = model(X_batch)\n",
        "\n",
        "plot_img_and_boundingbox(image, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytHrhFV8aX-C"
      },
      "outputs": [],
      "source": [
        "plot_img_and_boundingbox(image,pred[0])\n",
        "print(pred)\n",
        "print(calculate_true_positives_in_batch(labels.view(1,4),pred[0].view(1,4))) # Need to change view since we dont have batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghHYl7RzIXDF"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}